{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNet_model():\n",
    "\n",
    "    def __init__(self, nb_layers:int):\n",
    "\n",
    "        #à compléter\n",
    "        inputWN = tf.keras.Input(shape = (audio_length, 256), name=\"WN Input\")\n",
    "\n",
    "        out = tf.keras.layers.Conv1D(padding=\"causal\")(inputWN)\n",
    "\n",
    "        skip_connections = []\n",
    "        for k in range(nb_layers):\n",
    "            out, skipx = self.__residual_block(out)\n",
    "            skip_connections.append(skipx)\n",
    "\n",
    "        out = tf.keras.layers.Add()(skip_connections)\n",
    "        out = tf.keras.layers.Activation('relu')(out)\n",
    "        out = tf.keras.layers.Conv1D(kernel_size=1, padding = \"same\")(out)\n",
    "        out = tf.keras.layers.Activation('relu')(out)\n",
    "        out = tf.keras.layers.Conv1D(kernel_size=1, padding = \"same\")(out)\n",
    "\n",
    "\n",
    "        outputWN =  tf.keras.layers.Activation('softmax', name=\"WN Output\")(out)\n",
    "\n",
    "        WNmodel = tf.keras.models.Model(inputs = inputWN, outputs = outputWN)\n",
    "        \n",
    "        return WNmodel\n",
    "\n",
    "\n",
    "    def __delated_conv(self, input, nb_dilatation : int) -> Conv1D :\n",
    "        for i in range(nb_dilatation):\n",
    "            delated_conv_f = tf.keras.layers.Conv1D(dilation_rate = 2**i) (delated_conv_f)\n",
    "\n",
    "\n",
    "    def __residual_block(x):\n",
    "        # x : output of the \n",
    "        # delated conv filter\n",
    "        delated_conv_f0 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2, dilation_rate = 2**0)(x)\n",
    "        delated_conv_f1 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**1)(delated_conv_f0)\n",
    "        delated_conv_f2 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**2)(delated_conv_f1)\n",
    "        delated_conv_f3 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**3)(delated_conv_f2)\n",
    "        delated_conv_f4 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**4)(delated_conv_f3)\n",
    "        delated_conv_f5 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**5)(delated_conv_f4)\n",
    "        delated_conv_f6 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**6)(delated_conv_f5)\n",
    "        delated_conv_f7 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**7)(delated_conv_f6)\n",
    "        delated_conv_f8 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**8)(delated_conv_f7)\n",
    "        delated_conv_f9 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**9)(delated_conv_f8)\n",
    "        tanh_out = tf.keras.layers.Activation('tanh')(delated_conv_f9)\n",
    "\n",
    "         # delated conv gate\n",
    "\n",
    "        delated_conv_g0 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2, dilation_rate = 2**0)(x)\n",
    "        delated_conv_g1 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**1)(delated_conv_g0)\n",
    "        delated_conv_g2 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**2)(delated_conv_g1)\n",
    "        delated_conv_g3 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**3)(delated_conv_g2)\n",
    "        delated_conv_g4 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**4)(delated_conv_g3)\n",
    "        delated_conv_g5 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**5)(delated_conv_g4)\n",
    "        delated_conv_g6 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**6)(delated_conv_g5)\n",
    "        delated_conv_g7 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**7)(delated_conv_g6)\n",
    "        delated_conv_g8 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**8)(delated_conv_g7)\n",
    "        delated_conv_g9 = tf.keras.layers.Conv1D(padding = \"causal\", kernel_size = 2,dilation_rate = 2**9)(delated_conv_g8)\n",
    "        sigmoid_out = tf.keras.layers.Activation('sigmoid')(delated_conv_g9)\n",
    "\n",
    "        # merge x tanh & sigmoid\n",
    "        multiply = tf.keras.layers.Multiply()([tanh_out, sigmoid_out])\n",
    "\n",
    "        # conv 1,1\n",
    "        resx = tf.keras.layers.Conv1D(kernel_size=1, padding='same')(multiply)\n",
    "        skipx = tf.keras.layers.Conv1D(kernel_size=1, padding='same')(multiply)\n",
    "        resx = tf.keras.layers.Add()([x, resx])\n",
    "\n",
    "        return resx, skipx\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
